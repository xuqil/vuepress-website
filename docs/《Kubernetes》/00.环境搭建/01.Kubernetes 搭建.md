---
title: Kubernetes 搭建
date: 2023-03-25 21:39:22
permalink: /pages/ea05cd/
categories:
  - 《Kubernetes》
  - 环境搭建
tags:
  - 
---

# 安装kubernetes

## 安装列表

```bash
docker-ce-19.03.9-3.el7
kubelet-1.19.0 
kubeadm-1.19.0  
kubectl-1.19.0
```

## 前置条件

### 基础配置

主机节点：

```bash
IP:  192.168.122.120     主机名：k8s-master    系统： centos 7.6      配置： 4C 4G
IP:  192.168.122.121     主机名：k8s-node1     系统： centos 7.6      配置： 2C 2G
IP:  192.168.122.122     主机名：k8s-node2     系统： centos 7.6      配置： 2C 2G
```

以下条件所有节点都要执行：

1. 配置yum源：使用国内yum源即可。

   1. 配置yum源：

      ```bash
      yum install -y wget vim
      mkdir /etc/yum.repos.d/bak && mv /etc/yum.repos.d/*.repo /etc/yum.repos.d/bak
      wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
      wget -O /etc/yum.repos.d/epel-7.repo http://mirrors.aliyun.com/repo/epel-7.repo 
      ```

   2. 配置kubernetes源

      ```bash
      cat <<EOF > /etc/yum.repos.d/kubernetes.repo
      [kubernetes]
      name=Kubernetes
      baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
      enabled=1
      gpgcheck=1
      repo_gpgcheck=1
      gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
      EOF
      ```

   3. 配置docker源

      ```bash
      wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo
      ```

   4. 清理cache

      ```bash
      yum clean all && yum makecache fast -y
      ```

      

2. 关闭防火墙：

   ```bash
   systemctl disable firewalld
   systemctl stop firewalld
   ```

3. 在主机上禁用SELinux（修改文件`/etc/sysconfig/selinux`，将`SELINUX=enforcing`修改为`SELINUX=disabled`），让容器可以读取主机文件系统。

   ```bash
   sed -i 's/SELINUX=permissive/SELINUX=disabled/' /etc/sysconfig/selinux
   sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/sysconfig/selinux
   
   sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config
   setenforce 0
   ```

   

4. 关闭`swap`系统交换区：

   ```bash
   sed -i 's/.*swap.*/#&/' /etc/fstab
   swapoff -a
   ```

5. 添加主机名与IP对应关系

   ```bash
   cat >> /etc/hosts << EOF
   192.168.122.120 k8s-master
   192.168.122.121 k8s-node1
   192.168.122.122 k8s-node2
   192.168.122.120 cluster-endpoint
   EOF
   ```

6. 设置主机名（分别在不同的主机执行）

   ```bash
   #设置 192.168.122.120主机主机名
   hostnamectl set-hostname  k8s-master
   
   #设置 192.168.122.121主机主机名
   hostnamectl set-hostname  k8s-node1
   
   #设置 192.168.122.122主机主机名
   hostnamectl set-hostname  k8s-node2
   ```

7. 将桥接的IPv4流量传递到iptables的链

   ```bash
   cat > /etc/sysctl.d/k8s.conf << EOF
   net.bridge.bridge-nf-call-ip6tables = 1
   net.bridge.bridge-nf-call-iptables = 1
   EOF
   
   
   sysctl --system
   ```

   

8. 然后重启主机：

   ```bash
   shutdown -r now
   ```

   

9. 使用命令`getenforce`验证SELinux状态。

   ```bash
   [root@k8s-master1 ~]# getenforce
   Disabled
   ```

### docker安装

1. 安装docker

   ```bash
   # 列举docker版本
   # yum list docker-ce --showduplicates | sort -r 
   yum install -y docker-ce-19.03.11 docker-ce-cli-19.03.11 containerd.io-1.2.13
   systemctl enable docker && systemctl start docker
   ```

2. 配置国内镜像

   ```bash
   echo '{"registry-mirrors":["https://registry.dodcker-cn.com"],"exec-opts": ["native.cgroupdriver=systemd"]}'>/etc/docker/daemon.json
   ```

3. 重启docker

   ```bash
   systemctl daemon-reload
   systemctl restart docker
   ```

   

## 使用kubeadm工具安装kubernetes

### 安装kubeadm

执行命令：

```bash 
yum install -y kubelet-1.19.0 kubeadm-1.19.0  kubectl-1.19.0  --disableexcludes=kubernetes
systemctl enable kubelet  && systemctl start kubelet 
```

### 修改kubeadm的默认配置

kubeadm的初始化控制平面（init）命令和加入节点（join）命令均可以通过指定的配置文件修改默认参数的值。kubeadm将配置文件以ConfigMap形式保存到集群中，便于后续的查询和升级工作。`kubeadm config`子命令提供了对这组功能的支持。

- `kubeadm config print init-defaults`：输出`kubeadm init`命令默认参数的内容。
- `kubeadm config print join-defaults`：输出`kubeadm join`命令默认参数的内容。
- `kubeadm config migrate`：在新旧版本之间进行配置转换。
- `kubeadm config images list`：列出所需的镜像列表。
- `kubeadm config images pull`：拉取镜像到本地。

例如，运行kubeadm config print init-defaults命令，可以获得默认的初始化参数文件：

```bash
[root@k8s-master ~]# kubeadm config print init-defaults > ini.default.yaml
```

对生成的文件进行编辑，可以按需生成合适的配置。例如，若需要自定义镜像的仓库地址、需要安装的Kubernetes版本号及Pod的IP地址范围，则可以将默认配置修改如下：

```yaml
apiVersion: kubeadm.k8s.io/v1beta2
...
imageRepository: k8s.gcr.io  #镜像的仓库地址
kind: ClusterConfiguration
kubernetesVersion: v1.19.0  #Kubernetes版本号
networking:
  podSubnet: 192.168.0.0/16  #Pod的IP地址范围
```

将上面的内容保存为`init-config.yaml`备用：

```yaml
apiVersion: kubeadm.k8s.io/v1beta2
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: abcdef.0123456789abcdef
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 1.2.3.4
  bindPort: 6443
nodeRegistration:
  criSocket: /var/run/dockershim.sock
  name: k8s-master
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
---
apiServer:
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta2
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controllerManager: {}
dns:
  type: CoreDNS
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: k8s.gcr.io
kind: ClusterConfiguration
kubernetesVersion: v1.19.0
networking:
  podSubnet: 192.168.0.0/16
  dnsDomain: cluster.local
  serviceSubnet: 10.96.0.0/12
scheduler: {}
```



### 下载Kubernetes的相关镜像

为了加快kubeadm创建集群的过程，可以预先将所需镜像下载完成。可以通过`kubeadm config images list`命令查看镜像列表，例如：

```bash
[root@k8s-master ~]# kubeadm config images list --config=init-config.yaml
I1031 03:54:59.572699   14132 version.go:252] remote version is much newer: v1.22.3; falling back to: stable-1.19
W1031 03:55:01.211175   14132 configset.go:348] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]
k8s.gcr.io/kube-apiserver:v1.19.0
k8s.gcr.io/kube-controller-manager:v1.19.0
k8s.gcr.io/kube-scheduler:v1.19.0
k8s.gcr.io/kube-proxy:v1.19.0
k8s.gcr.io/pause:3.2
k8s.gcr.io/etcd:3.4.9-1
k8s.gcr.io/coredns:1.7.0
```

如果无法访问k8s.gcr.io，则可以使用国内镜像托管站点进行下载，例如https://registry.dodcker-cn.com，这可以通过修改Docker服务的配置文件（默认为`/etc/docker/daemon.json`）进行设置，例如：

```json
{"registry-mirrors":["https://registry.dodcker-cn.com"]}
```

然后，使用`kubeadm config images pull`命令或者`docker pull`命令下载上述镜像，例如：

```bash
[root@k8s-master ~]# kubeadm config images pull --config=init-config.yaml
```

这里使用`docker pull`下载相关镜像，下载成功后通过docker tag命令修改镜像的标签：

*提示： gcr.io项目对应的阿里镜像：http://registry.aliyuncs.com/google_containers，gcr.io项目docker对应的镜像源：http://docker.io/mirrorgooglecontainers和http://docker.io/google_containers*

如果将`imageRepository: k8s.gcr.io`改为`imageRepository: registry.aliyuncs.com/google_container`则不需要修改镜像标签

```bash
#下载镜像
docker pull registry.aliyuncs.com/google_containers/kube-apiserver:v1.19.0
docker pull registry.aliyuncs.com/google_containers/kube-controller-manager:v1.19.0
docker pull registry.aliyuncs.com/google_containers/kube-scheduler:v1.19.0
docker pull registry.aliyuncs.com/google_containers/kube-proxy:v1.19.0
docker pull registry.aliyuncs.com/google_containers/pause:3.2
docker pull registry.aliyuncs.com/google_containers/etcd:3.4.9-1
docker pull registry.aliyuncs.com/google_containers/coredns:1.7.0

#修改镜像标签
docker tag registry.aliyuncs.com/google_containers/kube-apiserver:v1.19.0 k8s.gcr.io/kube-apiserver:v1.19.0
docker tag registry.aliyuncs.com/google_containers/kube-controller-manager:v1.19.0 k8s.gcr.io/kube-controller-manager:v1.19.0
docker tag registry.aliyuncs.com/google_containers/kube-scheduler:v1.19.0 k8s.gcr.io/kube-scheduler:v1.19.0
docker tag registry.aliyuncs.com/google_containers/kube-proxy:v1.19.0 k8s.gcr.io/kube-proxy:v1.19.0
docker tag registry.aliyuncs.com/google_containers/pause:3.2 k8s.gcr.io/pause:3.2
docker tag registry.aliyuncs.com/google_containers/etcd:3.4.9-1 k8s.gcr.io/etcd:3.4.9-1
docker tag registry.aliyuncs.com/google_containers/coredns:1.7.0 k8s.gcr.io/coredns:1.7.0

#删除旧镜像
docker rmi registry.aliyuncs.com/google_containers/kube-apiserver:v1.19.0
docker rmi registry.aliyuncs.com/google_containers/kube-controller-manager:v1.19.0
docker rmi registry.aliyuncs.com/google_containers/kube-scheduler:v1.19.0
docker rmi registry.aliyuncs.com/google_containers/kube-proxy:v1.19.0
docker rmi registry.aliyuncs.com/google_containers/pause:3.2
docker rmi registry.aliyuncs.com/google_containers/etcd:3.4.9-1
docker rmi registry.aliyuncs.com/google_containers/coredns:1.7.0

#保存镜像
docker save -o  ./k8s1.19.0-images.tar k8s.gcr.io/kube-apiserver:v1.19.0 k8s.gcr.io/kube-controller-manager:v1.19.0 k8s.gcr.io/kube-scheduler:v1.19.0 k8s.gcr.io/kube-proxy:v1.19.0 k8s.gcr.io/pause:3.2 k8s.gcr.io/etcd:3.4.9-1 k8s.gcr.io/coredns:1.7.0
```

### 运行`kubeadm init`命令安装Master节点

此，准备工作已经就绪，运行`kubeadm init`命令即可一键安装Kubernetes的Master节点，也称之为Kubernetes控制平面（Control Plane）。

在开始之前需要注意：kubeadm的安装过程不涉及网络插件（CNI）的初始化，因此kubeadm初步安装完成的集群**不具备网络功能**，任何Pod（包括自带的CoreDNS）都无法正常工作。**而网络插件的安装往往对kubeadm init命令的参数有一定要求。例如，安装Calico插件时需要指定`--pod-network-cidr=192.168.0.0/16`**。关于安装CNI网络插件的更多内容，可参考官方文档的说明。

`kubeadm init`命令在执行具体的安装操作之前，会执行一系列被称为`pre-flight checks`的系统预检查，以确保主机环境符合安装要求，如果检查失败就直接终止，不再进行init操作。用户可以通过`kubeadm init phase preflight`命令执行预检查操作，确保系统就绪后再执行`init`操作。如果不希望执行预检查，则也可以为`kubeadm init`命令添加`--ignore-preflight-errors`参数进行关闭。

Kubernetes默认设置cgroup驱动（cgroupdriver）为“systemd”，而Docker服务的cgroup驱动默认值为“cgroupfs”，建议将其修改为“systemd”，与Kubernetes保持一致。这可以通过修改Docker服务的配置文件（默认为`/etc/docker/daemon.json`）进行设置：

```json
{
    "exec-opts": ["native.cgroupdriver=systemd"],
    ...
}
```

然后执行：

```bash
systemctl daemon-reload
systemctl restart docker
```

准备工作就绪之后，就可以运行`kubeadm init`命令，使用之前创建的配置文件一键安装Master节点（控制平面）了：

```bash
kubeadm init --config=init-config.yaml
#sudo kubeadm init --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.19.0 --apiserver-advertise-address 192.168.122.120 --pod-network-cidr=192.168.0.0/16 --token-ttl 0 --control-plane-endpoint cluster-endpoint
```

看到“Your Kubernetes control-plane has initialized successfully！”的提示，就说明Master节点（控制平面）已经安装成功了。

接下来就可以通过kubectl命令行工具访问集群进行操作了**。由于kubeadm默认使用CA证书，所以需要为kubectl配置证书才能访问Master。**

按照安装成功的提示，**非root用户**可以将`admin.conf`配置文件复制到HOME目录的`.kube`子目录下，命令如下：

```bash

```

如果用户是root，则也可以通过设置环境变量KUBECONFIG完成kubectl的配置：

```bash
```

然后就可以使用kubectl命令行工具对Kubernetes集群进行访问和操作了。

到此，Kubernetes的Master节点已经可以工作了，但在集群内还是没有可用的Worker Node，并缺乏容器网络的配置。

接下来安装Worker Node，需要用到kubeadm init命令运行完成后的最后几行提示信息，其中包含将节点加入集群的命令（kubeadm join）和所需的Token。

### 检查各组件

```bash
[root@k8s-master ~]# kubectl get cs
Warning: v1 ComponentStatus is deprecated in v1.19+
NAME                 STATUS      MESSAGE                                                                                       ERROR
controller-manager   Unhealthy   Get "http://127.0.0.1:10252/healthz": dial tcp 127.0.0.1:10252: connect: connection refused
scheduler            Unhealthy   Get "http://127.0.0.1:10251/healthz": dial tcp 127.0.0.1:10251: connect: connection refused
etcd-0               Healthy     {"health":"true"}

```

遇到`dial tcp 127.0.0.1:10252: connect: connection refused`问题。

解决方式：

是`/etc/kubernetes/manifests/`下的`kube-controller-manager.yaml`和`kube-scheduler.yaml`的port为0导致的，需要将它注释掉。

```yaml
spec:
  containers:
  - command:
    - kube-scheduler
    - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf
    - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf
    - --bind-address=127.0.0.1
    - --kubeconfig=/etc/kubernetes/scheduler.conf
    - --leader-elect=true
    #- --port=0

```

重新查看

```bash
[root@k8s-master manifests]# kubectl get cs
Warning: v1 ComponentStatus is deprecated in v1.19+
NAME                 STATUS    MESSAGE             ERROR
scheduler            Healthy   ok
controller-manager   Healthy   ok
etcd-0               Healthy   {"health":"true"}

```



## 安装网络创建Calio

https://kuboard.cn/install-script/calico/calico-3.13.1.yam
